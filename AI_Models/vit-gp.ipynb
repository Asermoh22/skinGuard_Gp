{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4ec0f1ee",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-05-04T17:03:00.607041Z",
     "iopub.status.busy": "2025-05-04T17:03:00.606745Z",
     "iopub.status.idle": "2025-05-04T17:04:04.120914Z",
     "shell.execute_reply": "2025-05-04T17:04:04.120003Z"
    },
    "papermill": {
     "duration": 63.520262,
     "end_time": "2025-05-04T17:04:04.123554",
     "exception": false,
     "start_time": "2025-05-04T17:03:00.603292",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Image counts by class:\n",
      "Eczema: 999 images\n",
      "Melanoma: 1000 images\n",
      "Basal Cell: 1000 images\n",
      "Seborrheic: 1000 images\n",
      "Atopic Dermatitis: 1000 images\n",
      "Melanocytic: 1000 images\n",
      "Benign Keratosis: 1201 images\n",
      "Warts Molluscum: 1000 images\n",
      "Psoriasis: 1000 images\n",
      "Tinea Ringworms Candidiasis: 990 images\n",
      "\n",
      "Renaming and consolidation complete!\n"
     ]
    }
   ],
   "source": [
    " import os\n",
    " import shutil\n",
    "\n",
    " # Input folder containing the images\n",
    " input_dir = r\"/kaggle/input/skin-disease-dataset/dataset/train\"\n",
    " # Output folder for renamed images\n",
    " output_dir = r\"/kaggle/working/renamed_train\"\n",
    "\n",
    " # Ensure the output directory exists\n",
    " os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    " # Dictionary to track counts for each class\n",
    " class_counts = {}\n",
    "\n",
    " # Traverse through each subdirectory\n",
    " for root, dirs, files in os.walk(input_dir):\n",
    "     for file_name in files:\n",
    "         # Full path of the image\n",
    "         img_path = os.path.join(root, file_name)\n",
    "\n",
    "         # Skip non-image files\n",
    "         if not file_name.lower().endswith(('.jpg', '.jpeg', '.png')):\n",
    "             print(f\"Skipping non-image file: {file_name}\")\n",
    "             continue\n",
    "\n",
    "         # Get the folder name (class name) as the class identifier\n",
    "         class_name = os.path.basename(root)\n",
    "\n",
    "         # Initialize or increment the count for this class\n",
    "         if class_name not in class_counts:\n",
    "             class_counts[class_name] = 1\n",
    "         else:\n",
    "             class_counts[class_name] += 1\n",
    "\n",
    "         # Generate new file name in the format ClassName(Count).Extension\n",
    "         count = class_counts[class_name]\n",
    "         ext = os.path.splitext(file_name)[1]  # Get file extension\n",
    "         new_name = f\"{class_name}({count}){ext}\"\n",
    "         new_path = os.path.join(output_dir, new_name)\n",
    "\n",
    "         # Copy and rename the file to the output directory\n",
    "         shutil.copy(img_path, new_path)\n",
    "\n",
    " # Print the total number of images for each class\n",
    " print(\"\\nImage counts by class:\")\n",
    " for class_name, count in class_counts.items():\n",
    "     print(f\"{class_name}: {count} images\")\n",
    "\n",
    " print(\"\\nRenaming and consolidation complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ff82e0f4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-04T17:04:04.128392Z",
     "iopub.status.busy": "2025-05-04T17:04:04.128150Z",
     "iopub.status.idle": "2025-05-04T17:04:04.136410Z",
     "shell.execute_reply": "2025-05-04T17:04:04.135668Z"
    },
    "papermill": {
     "duration": 0.01188,
     "end_time": "2025-05-04T17:04:04.137518",
     "exception": false,
     "start_time": "2025-05-04T17:04:04.125638",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n# 9 Classes\\nimport os\\nimport pandas as pd\\nimport numpy as np\\nimport math\\nimport random\\nfrom sklearn.metrics import confusion_matrix\\nfrom tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\\nimport matplotlib.pyplot as plt\\nimport cv2\\nfrom sklearn.model_selection import train_test_split\\nfrom transformers import ViTForImageClassification, SwinForImageClassification\\nimport torch\\nfrom torch.utils.data import DataLoader, Dataset\\nfrom torchvision import transforms\\n\\n# Define class mapping\\nclass_mapping = {\\n    \"Seborrheic\": 0,\\n    \"Melanocytic\": 1,\\n    \"Melanoma\": 2,\\n    \"Eczema\": 3,\\n    \"Basal_Cell\": 4,\\n    \"Psoriasis\": 5,\\n    \"Tinea_Ringworms_Candidiasis\": 6,\\n    \"Warts_Molluscum\": 7,\\n    \"Atopic_Dermatitis\" : 8,\\n}\\n\\n# Preprocess images: resize and normalize\\ndef preprocess_image(image_path):\\n    image = cv2.imread(image_path)\\n    if image is None:\\n        print(f\"Warning: {image_path} could not be loaded.\")\\n        return None\\n\\n    resized_image = cv2.resize(image, (224, 224))  # Resize to 224x224\\n    img_normalized = resized_image.astype(\\'float32\\') / 255.0  # Normalize to [0, 1]\\n    return img_normalized\\n\\ndef load_data_from_single_folder(folder):\\n    images = []\\n    labels = []\\n\\n    for image_name in os.listdir(folder):\\n        image_path = os.path.join(folder, image_name)\\n\\n        # Check if file is an image\\n        if image_name.lower().endswith((\\'.png\\', \\'.jpg\\', \\'.jpeg\\')):\\n            # Extract the label from the filename (before the parentheses)\\n            label = image_name.split(\\'(\\')[0].strip().replace(\\' \\', \\'_\\')  # Handle spaces and extract class name\\n            \\n            if label in class_mapping:\\n                label_index = class_mapping[label]  # Map label to integer\\n            else:\\n                continue\\n\\n            # Preprocess the image\\n            preprocessed_image = preprocess_image(image_path)\\n            if preprocessed_image is not None:\\n                images.append(preprocessed_image)\\n                labels.append(label_index)\\n\\n    print(f\"Loaded {len(images)} images and {len(labels)} labels.\")\\n    return np.array(images), np.array(labels)\\n\\n# Data augmentation transforms\\ntrain_transform = transforms.Compose([\\n    transforms.ToTensor(),\\n    transforms.RandomHorizontalFlip(),\\n    transforms.RandomAffine(degrees=10, translate=(0.1, 0.1)),\\n    transforms.RandomResizedCrop(224, scale=(0.9, 1.0)),\\n    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\\n])\\n\\ntest_transform = transforms.Compose([\\n    transforms.ToTensor(),\\n    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\\n])\\n\\n# Paths for train folder\\ntrain_folder = r\\'/kaggle/working/renamed_train\\'\\n\\n# Load data\\nX_train, y_train = load_data_from_single_folder(train_folder)\\n\\n# === Step 6: Class Distribution Analysis ===\\nclass_counts = pd.Series(y_train).value_counts()\\nclass_names = {v: k for k, v in class_mapping.items()}  # Reverse the mapping\\nclass_counts_named = class_counts.rename(index=class_names)\\n\\nprint(\"\\nClass counts (class names):\")\\nprint(class_counts_named)\\n\\n# === Step 7: Balance Classes to Max Class Size Using Augmentation ===\\nmax_class_size = class_counts.max()  # Maximum size among all classes\\naugmented_images = []\\naugmented_labels = []\\n# Create augmented images for each class\\nfor label in np.unique(y_train):\\n    class_images = X_train[y_train == label]\\n    current_class_size = class_counts[label]\\n    \\n    for _ in range(max_class_size - current_class_size):\\n        # Select a random image from the class\\n        img = class_images[random.randint(0, current_class_size - 1)]\\n        \\n        # Apply random transformations\\n        img_tensor = torch.from_numpy(img.transpose(2, 0, 1)).float()\\n        img_tensor = train_transform(img_tensor.numpy().transpose(1, 2, 0))\\n        \\n        augmented_images.append(img_tensor.numpy().transpose(1, 2, 0))\\n        augmented_labels.append(label)\\n\\n# If augmented images are created, concatenate them with the original data\\nif augmented_images:  # Ensure there are augmented images to add\\n    X_train = np.concatenate([X_train, np.array(augmented_images)])\\n    y_train = np.concatenate([y_train, np.array(augmented_labels)])\\n\\n# Check new class distribution\\nnew_class_counts = pd.Series(y_train).value_counts()\\nnew_class_counts_named = new_class_counts.rename(index=class_names)\\n\\nprint(\"\\nNew class counts after augmentation (class names):\")\\nprint(new_class_counts_named)\\n\\n# Split the dataset into training and validation sets (80% train, 20% test)\\nX_train, X_test, y_train, y_test = train_test_split(X_train, y_train, test_size=0.2, random_state=42, stratify=y_train)\\n\\n# Convert data to PyTorch tensors\\nX_train = torch.tensor(X_train.transpose(0, 3, 1, 2), dtype=torch.float32)  # Convert to [N, C, H, W]\\nX_test = torch.tensor(X_test.transpose(0, 3, 1, 2), dtype=torch.float32)\\ny_train = torch.tensor(y_train, dtype=torch.long)\\ny_test = torch.tensor(y_test, dtype=torch.long)\\n\\n# Create a PyTorch Dataset\\nclass CustomDataset(Dataset):\\n    def __init__(self, images, labels):\\n        self.images = images\\n        self.labels = labels\\n\\n    def __len__(self):\\n        return len(self.images)\\n\\n    def __getitem__(self, idx):\\n        return self.images[idx], self.labels[idx]\\n\\ntrain_dataset = CustomDataset(X_train, y_train)\\ntest_dataset = CustomDataset(X_test, y_test)\\n\\n# Create DataLoaders\\ntrain_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\\ntest_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\\n\\nmodel = SwinForImageClassification.from_pretrained(\\n    \"microsoft/swin-base-patch4-window7-224-in22k\",\\n    num_labels=len(class_mapping),\\n    ignore_mismatched_sizes=True,\\n)\\n\\n# Move model to GPU if available\\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\\nmodel.to(device)\\n\\n# Define optimizer and loss function\\noptimizer = torch.optim.AdamW(model.parameters(), lr=7e-6)\\ncriterion = torch.nn.CrossEntropyLoss()\\n\\n# Training loop with best accuracy tracking\\ndef train_model(model, train_loader, test_loader, optimizer, criterion, epochs=10):\\n    best_accuracy = 0.0\\n    best_epoch = 0\\n\\n    for epoch in range(epochs):\\n        model.train()\\n        train_loss = 0.0\\n        correct = 0\\n        total = 0\\n\\n        for images, labels in train_loader:\\n            images, labels = images.to(device), labels.to(device)\\n\\n            # Forward pass\\n            outputs = model(images).logits\\n            loss = criterion(outputs, labels)\\n\\n            # Backward pass and optimization\\n            optimizer.zero_grad()\\n            loss.backward()\\n            optimizer.step()\\n\\n            train_loss += loss.item()\\n            _, predicted = outputs.max(1)\\n            total += labels.size(0)\\n            correct += predicted.eq(labels).sum().item()\\n\\n        # Print training accuracy\\n        train_accuracy = 100.0 * correct / total\\n        print(f\"Epoch [{epoch+1}/{epochs}], Loss: {train_loss/len(train_loader):.4f}, Accuracy: {train_accuracy:.2f}%\")\\n\\n        # Validation\\n        model.eval()\\n        val_loss = 0.0\\n        correct = 0\\n        total = 0\\n\\n        with torch.no_grad():\\n            for images, labels in test_loader:\\n                images, labels = images.to(device), labels.to(device)\\n\\n                outputs = model(images).logits\\n                loss = criterion(outputs, labels)\\n\\n                val_loss += loss.item()\\n                _, predicted = outputs.max(1)\\n                total += labels.size(0)\\n                correct += predicted.eq(labels).sum().item()\\n\\n        # Print validation accuracy\\n        val_accuracy = 100.0 * correct / total\\n        print(f\"Validation Loss: {val_loss/len(test_loader):.4f}, Validation Accuracy: {val_accuracy:.2f}%\")\\n\\n        # Check if the current validation accuracy is the best\\n        if val_accuracy > best_accuracy:\\n            best_accuracy = val_accuracy\\n            best_epoch = epoch + 1\\n\\n    # Print the best validation accuracy and corresponding epoch\\n    print(f\"Best Validation Accuracy: {best_accuracy:.2f}% at Epoch {best_epoch}\")\\n\\n# Train the model\\ntrain_model(model, train_loader, test_loader, optimizer, criterion, epochs=20)\\n\\n# Evaluate the model\\nmodel.eval()\\ny_true = []\\ny_pred = []\\n\\nwith torch.no_grad():\\n    for images, labels in test_loader:\\n        images, labels = images.to(device), labels.to(device)\\n        outputs = model(images).logits\\n        _, predicted = outputs.max(1)\\n        y_true.extend(labels.cpu().numpy())\\n        y_pred.extend(predicted.cpu().numpy())\\n\\n# Confusion matrix\\nconf_matrix = confusion_matrix(y_true, y_pred)\\nprint(\"Confusion Matrix:\")\\nprint(conf_matrix)\\n\\n# Calculate test accuracy\\ntest_accuracy = 100.0 * np.mean(np.array(y_true) == np.array(y_pred))\\n\\n# Round to the nearest ceiling integer\\ntest_accuracy_ceil = math.ceil(test_accuracy)\\nprint(f\"Test Accuracy: {test_accuracy_ceil}%\")\\n\\n# Print the first 10 predictions and actual class names from test set\\nlabel_to_class = {v: k for k, v in class_mapping.items()}\\nfor i in range(10):\\n    predicted_class = label_to_class[y_pred[i]]  \\n    actual_class = label_to_class[y_true[i]]    \\n    print(f\"Predicted: {predicted_class}, Actual: {actual_class}\")\\n    \\n# Save the model\\nmodel_save_path = \"/kaggle/working/vit_skin_disease_model.pth\"\\ntorch.save(model.state_dict(), model_save_path)\\nprint(f\"Model saved to {model_save_path}\")'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "# 9 Classes\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "import random\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "from sklearn.model_selection import train_test_split\n",
    "from transformers import ViTForImageClassification, SwinForImageClassification\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torchvision import transforms\n",
    "\n",
    "# Define class mapping\n",
    "class_mapping = {\n",
    "    \"Seborrheic\": 0,\n",
    "    \"Melanocytic\": 1,\n",
    "    \"Melanoma\": 2,\n",
    "    \"Eczema\": 3,\n",
    "    \"Basal_Cell\": 4,\n",
    "    \"Psoriasis\": 5,\n",
    "    \"Tinea_Ringworms_Candidiasis\": 6,\n",
    "    \"Warts_Molluscum\": 7,\n",
    "    \"Atopic_Dermatitis\" : 8,\n",
    "}\n",
    "\n",
    "# Preprocess images: resize and normalize\n",
    "def preprocess_image(image_path):\n",
    "    image = cv2.imread(image_path)\n",
    "    if image is None:\n",
    "        print(f\"Warning: {image_path} could not be loaded.\")\n",
    "        return None\n",
    "\n",
    "    resized_image = cv2.resize(image, (224, 224))  # Resize to 224x224\n",
    "    img_normalized = resized_image.astype('float32') / 255.0  # Normalize to [0, 1]\n",
    "    return img_normalized\n",
    "\n",
    "def load_data_from_single_folder(folder):\n",
    "    images = []\n",
    "    labels = []\n",
    "\n",
    "    for image_name in os.listdir(folder):\n",
    "        image_path = os.path.join(folder, image_name)\n",
    "\n",
    "        # Check if file is an image\n",
    "        if image_name.lower().endswith(('.png', '.jpg', '.jpeg')):\n",
    "            # Extract the label from the filename (before the parentheses)\n",
    "            label = image_name.split('(')[0].strip().replace(' ', '_')  # Handle spaces and extract class name\n",
    "            \n",
    "            if label in class_mapping:\n",
    "                label_index = class_mapping[label]  # Map label to integer\n",
    "            else:\n",
    "                continue\n",
    "\n",
    "            # Preprocess the image\n",
    "            preprocessed_image = preprocess_image(image_path)\n",
    "            if preprocessed_image is not None:\n",
    "                images.append(preprocessed_image)\n",
    "                labels.append(label_index)\n",
    "\n",
    "    print(f\"Loaded {len(images)} images and {len(labels)} labels.\")\n",
    "    return np.array(images), np.array(labels)\n",
    "\n",
    "# Data augmentation transforms\n",
    "train_transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomAffine(degrees=10, translate=(0.1, 0.1)),\n",
    "    transforms.RandomResizedCrop(224, scale=(0.9, 1.0)),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "])\n",
    "\n",
    "test_transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "])\n",
    "\n",
    "# Paths for train folder\n",
    "train_folder = r'/kaggle/working/renamed_train'\n",
    "\n",
    "# Load data\n",
    "X_train, y_train = load_data_from_single_folder(train_folder)\n",
    "\n",
    "# === Step 6: Class Distribution Analysis ===\n",
    "class_counts = pd.Series(y_train).value_counts()\n",
    "class_names = {v: k for k, v in class_mapping.items()}  # Reverse the mapping\n",
    "class_counts_named = class_counts.rename(index=class_names)\n",
    "\n",
    "print(\"\\nClass counts (class names):\")\n",
    "print(class_counts_named)\n",
    "\n",
    "# === Step 7: Balance Classes to Max Class Size Using Augmentation ===\n",
    "max_class_size = class_counts.max()  # Maximum size among all classes\n",
    "augmented_images = []\n",
    "augmented_labels = []\n",
    "# Create augmented images for each class\n",
    "for label in np.unique(y_train):\n",
    "    class_images = X_train[y_train == label]\n",
    "    current_class_size = class_counts[label]\n",
    "    \n",
    "    for _ in range(max_class_size - current_class_size):\n",
    "        # Select a random image from the class\n",
    "        img = class_images[random.randint(0, current_class_size - 1)]\n",
    "        \n",
    "        # Apply random transformations\n",
    "        img_tensor = torch.from_numpy(img.transpose(2, 0, 1)).float()\n",
    "        img_tensor = train_transform(img_tensor.numpy().transpose(1, 2, 0))\n",
    "        \n",
    "        augmented_images.append(img_tensor.numpy().transpose(1, 2, 0))\n",
    "        augmented_labels.append(label)\n",
    "\n",
    "# If augmented images are created, concatenate them with the original data\n",
    "if augmented_images:  # Ensure there are augmented images to add\n",
    "    X_train = np.concatenate([X_train, np.array(augmented_images)])\n",
    "    y_train = np.concatenate([y_train, np.array(augmented_labels)])\n",
    "\n",
    "# Check new class distribution\n",
    "new_class_counts = pd.Series(y_train).value_counts()\n",
    "new_class_counts_named = new_class_counts.rename(index=class_names)\n",
    "\n",
    "print(\"\\nNew class counts after augmentation (class names):\")\n",
    "print(new_class_counts_named)\n",
    "\n",
    "# Split the dataset into training and validation sets (80% train, 20% test)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_train, y_train, test_size=0.2, random_state=42, stratify=y_train)\n",
    "\n",
    "# Convert data to PyTorch tensors\n",
    "X_train = torch.tensor(X_train.transpose(0, 3, 1, 2), dtype=torch.float32)  # Convert to [N, C, H, W]\n",
    "X_test = torch.tensor(X_test.transpose(0, 3, 1, 2), dtype=torch.float32)\n",
    "y_train = torch.tensor(y_train, dtype=torch.long)\n",
    "y_test = torch.tensor(y_test, dtype=torch.long)\n",
    "\n",
    "# Create a PyTorch Dataset\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, images, labels):\n",
    "        self.images = images\n",
    "        self.labels = labels\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.images[idx], self.labels[idx]\n",
    "\n",
    "train_dataset = CustomDataset(X_train, y_train)\n",
    "test_dataset = CustomDataset(X_test, y_test)\n",
    "\n",
    "# Create DataLoaders\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "model = SwinForImageClassification.from_pretrained(\n",
    "    \"microsoft/swin-base-patch4-window7-224-in22k\",\n",
    "    num_labels=len(class_mapping),\n",
    "    ignore_mismatched_sizes=True,\n",
    ")\n",
    "\n",
    "# Move model to GPU if available\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "\n",
    "# Define optimizer and loss function\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=7e-6)\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "# Training loop with best accuracy tracking\n",
    "def train_model(model, train_loader, test_loader, optimizer, criterion, epochs=10):\n",
    "    best_accuracy = 0.0\n",
    "    best_epoch = 0\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        train_loss = 0.0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "\n",
    "        for images, labels in train_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "            # Forward pass\n",
    "            outputs = model(images).logits\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "            # Backward pass and optimization\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            train_loss += loss.item()\n",
    "            _, predicted = outputs.max(1)\n",
    "            total += labels.size(0)\n",
    "            correct += predicted.eq(labels).sum().item()\n",
    "\n",
    "        # Print training accuracy\n",
    "        train_accuracy = 100.0 * correct / total\n",
    "        print(f\"Epoch [{epoch+1}/{epochs}], Loss: {train_loss/len(train_loader):.4f}, Accuracy: {train_accuracy:.2f}%\")\n",
    "\n",
    "        # Validation\n",
    "        model.eval()\n",
    "        val_loss = 0.0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for images, labels in test_loader:\n",
    "                images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "                outputs = model(images).logits\n",
    "                loss = criterion(outputs, labels)\n",
    "\n",
    "                val_loss += loss.item()\n",
    "                _, predicted = outputs.max(1)\n",
    "                total += labels.size(0)\n",
    "                correct += predicted.eq(labels).sum().item()\n",
    "\n",
    "        # Print validation accuracy\n",
    "        val_accuracy = 100.0 * correct / total\n",
    "        print(f\"Validation Loss: {val_loss/len(test_loader):.4f}, Validation Accuracy: {val_accuracy:.2f}%\")\n",
    "\n",
    "        # Check if the current validation accuracy is the best\n",
    "        if val_accuracy > best_accuracy:\n",
    "            best_accuracy = val_accuracy\n",
    "            best_epoch = epoch + 1\n",
    "\n",
    "    # Print the best validation accuracy and corresponding epoch\n",
    "    print(f\"Best Validation Accuracy: {best_accuracy:.2f}% at Epoch {best_epoch}\")\n",
    "\n",
    "# Train the model\n",
    "train_model(model, train_loader, test_loader, optimizer, criterion, epochs=20)\n",
    "\n",
    "# Evaluate the model\n",
    "model.eval()\n",
    "y_true = []\n",
    "y_pred = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for images, labels in test_loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        outputs = model(images).logits\n",
    "        _, predicted = outputs.max(1)\n",
    "        y_true.extend(labels.cpu().numpy())\n",
    "        y_pred.extend(predicted.cpu().numpy())\n",
    "\n",
    "# Confusion matrix\n",
    "conf_matrix = confusion_matrix(y_true, y_pred)\n",
    "print(\"Confusion Matrix:\")\n",
    "print(conf_matrix)\n",
    "\n",
    "# Calculate test accuracy\n",
    "test_accuracy = 100.0 * np.mean(np.array(y_true) == np.array(y_pred))\n",
    "\n",
    "# Round to the nearest ceiling integer\n",
    "test_accuracy_ceil = math.ceil(test_accuracy)\n",
    "print(f\"Test Accuracy: {test_accuracy_ceil}%\")\n",
    "\n",
    "# Print the first 10 predictions and actual class names from test set\n",
    "label_to_class = {v: k for k, v in class_mapping.items()}\n",
    "for i in range(10):\n",
    "    predicted_class = label_to_class[y_pred[i]]  \n",
    "    actual_class = label_to_class[y_true[i]]    \n",
    "    print(f\"Predicted: {predicted_class}, Actual: {actual_class}\")\n",
    "    \n",
    "# Save the model\n",
    "model_save_path = \"/kaggle/working/vit_skin_disease_model.pth\"\n",
    "torch.save(model.state_dict(), model_save_path)\n",
    "print(f\"Model saved to {model_save_path}\")'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "56abdfb8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-04T17:04:04.142875Z",
     "iopub.status.busy": "2025-05-04T17:04:04.142640Z",
     "iopub.status.idle": "2025-05-04T19:59:59.931689Z",
     "shell.execute_reply": "2025-05-04T19:59:59.930655Z"
    },
    "papermill": {
     "duration": 10555.793462,
     "end_time": "2025-05-04T19:59:59.933174",
     "exception": false,
     "start_time": "2025-05-04T17:04:04.139712",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/albumentations/__init__.py:24: UserWarning: A new version of Albumentations is available: 2.0.6 (you have 1.4.20). Upgrade using: pip install -U albumentations. To disable automatic update checks, set the environment variable NO_ALBUMENTATIONS_UPDATE to 1.\n",
      "  check_for_updates()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Original class distribution:\n",
      "Class 4: 1000 samples\n",
      "Class 2: 1000 samples\n",
      "Class 3: 999 samples\n",
      "Class 0: 1000 samples\n",
      "Class 1: 1000 samples\n",
      "Class 6: 990 samples\n",
      "Class 7: 1000 samples\n",
      "Class 5: 1000 samples\n",
      "Class 8: 1000 samples\n",
      "Class 9: 1201 samples\n",
      "\n",
      "Balanced class distribution:\n",
      "Class 4: 1500 samples\n",
      "Class 2: 1500 samples\n",
      "Class 3: 1500 samples\n",
      "Class 0: 1500 samples\n",
      "Class 1: 1500 samples\n",
      "Class 6: 1500 samples\n",
      "Class 7: 1500 samples\n",
      "Class 5: 1500 samples\n",
      "Class 8: 1500 samples\n",
      "Class 9: 1500 samples\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d10b95a48c4b471aaea6eaa55870f3e4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/71.8k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2ff6424ce1fc443f9b765a24f8541c80",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/352M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of SwinForImageClassification were not initialized from the model checkpoint at microsoft/swin-base-patch4-window7-224 and are newly initialized because the shapes did not match:\n",
      "- classifier.bias: found shape torch.Size([1000]) in the checkpoint and torch.Size([10]) in the model instantiated\n",
      "- classifier.weight: found shape torch.Size([1000, 1024]) in the checkpoint and torch.Size([10, 1024]) in the model instantiated\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b682ab312d04408393793ffc5b9b8d10",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/69.7k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "81faa4d82b5846889333f2f505f40328",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/346M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of ViTForImageClassification were not initialized from the model checkpoint at google/vit-base-patch16-224 and are newly initialized because the shapes did not match:\n",
      "- classifier.bias: found shape torch.Size([1000]) in the checkpoint and torch.Size([10]) in the model instantiated\n",
      "- classifier.weight: found shape torch.Size([1000, 768]) in the checkpoint and torch.Size([10, 768]) in the model instantiated\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Starting training...\n",
      "\n",
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 375/375 [08:02<00:00,  1.29s/it]\n",
      "Validation: 100%|██████████| 94/94 [00:40<00:00,  2.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.8305 | Train Acc: 70.12%\n",
      "Val Loss: 0.5124 | Val Acc: 81.43%\n",
      "\n",
      "Epoch 2/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 375/375 [08:01<00:00,  1.28s/it]\n",
      "Validation: 100%|██████████| 94/94 [00:40<00:00,  2.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.4346 | Train Acc: 84.46%\n",
      "Val Loss: 0.3806 | Val Acc: 87.10%\n",
      "\n",
      "Epoch 3/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 375/375 [08:01<00:00,  1.28s/it]\n",
      "Validation: 100%|██████████| 94/94 [00:41<00:00,  2.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.2762 | Train Acc: 90.72%\n",
      "Val Loss: 0.3337 | Val Acc: 88.93%\n",
      "\n",
      "Epoch 4/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 375/375 [08:02<00:00,  1.29s/it]\n",
      "Validation: 100%|██████████| 94/94 [00:40<00:00,  2.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.1837 | Train Acc: 93.74%\n",
      "Val Loss: 0.2974 | Val Acc: 90.33%\n",
      "\n",
      "Epoch 5/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 375/375 [08:02<00:00,  1.29s/it]\n",
      "Validation: 100%|██████████| 94/94 [00:41<00:00,  2.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.1405 | Train Acc: 95.47%\n",
      "Val Loss: 0.2755 | Val Acc: 90.93%\n",
      "\n",
      "Epoch 6/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 375/375 [08:02<00:00,  1.29s/it]\n",
      "Validation: 100%|██████████| 94/94 [00:40<00:00,  2.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.1133 | Train Acc: 96.10%\n",
      "Val Loss: 0.2451 | Val Acc: 92.57%\n",
      "\n",
      "Epoch 7/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 375/375 [08:02<00:00,  1.29s/it]\n",
      "Validation: 100%|██████████| 94/94 [00:40<00:00,  2.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0811 | Train Acc: 97.25%\n",
      "Val Loss: 0.3094 | Val Acc: 91.80%\n",
      "\n",
      "Epoch 8/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 375/375 [08:01<00:00,  1.28s/it]\n",
      "Validation: 100%|██████████| 94/94 [00:40<00:00,  2.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0841 | Train Acc: 97.10%\n",
      "Val Loss: 0.2917 | Val Acc: 91.93%\n",
      "\n",
      "Epoch 9/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 375/375 [08:01<00:00,  1.28s/it]\n",
      "Validation: 100%|██████████| 94/94 [00:40<00:00,  2.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0753 | Train Acc: 97.51%\n",
      "Val Loss: 0.3034 | Val Acc: 91.63%\n",
      "\n",
      "Epoch 10/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 375/375 [08:02<00:00,  1.29s/it]\n",
      "Validation: 100%|██████████| 94/94 [00:40<00:00,  2.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0691 | Train Acc: 97.83%\n",
      "Val Loss: 0.2908 | Val Acc: 92.47%\n",
      "\n",
      "Epoch 11/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 375/375 [08:02<00:00,  1.29s/it]\n",
      "Validation: 100%|██████████| 94/94 [00:40<00:00,  2.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0575 | Train Acc: 98.10%\n",
      "Val Loss: 0.2947 | Val Acc: 92.70%\n",
      "\n",
      "Epoch 12/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 375/375 [08:01<00:00,  1.29s/it]\n",
      "Validation: 100%|██████████| 94/94 [00:41<00:00,  2.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0614 | Train Acc: 97.93%\n",
      "Val Loss: 0.2798 | Val Acc: 92.70%\n",
      "\n",
      "Epoch 13/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 375/375 [08:02<00:00,  1.29s/it]\n",
      "Validation: 100%|██████████| 94/94 [00:40<00:00,  2.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0559 | Train Acc: 98.03%\n",
      "Val Loss: 0.2926 | Val Acc: 92.37%\n",
      "\n",
      "Epoch 14/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 375/375 [08:02<00:00,  1.29s/it]\n",
      "Validation: 100%|██████████| 94/94 [00:40<00:00,  2.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0514 | Train Acc: 98.10%\n",
      "Val Loss: 0.2770 | Val Acc: 93.17%\n",
      "\n",
      "Epoch 15/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 375/375 [08:02<00:00,  1.29s/it]\n",
      "Validation: 100%|██████████| 94/94 [00:40<00:00,  2.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0430 | Train Acc: 98.50%\n",
      "Val Loss: 0.3070 | Val Acc: 92.47%\n",
      "\n",
      "Epoch 16/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 375/375 [08:02<00:00,  1.29s/it]\n",
      "Validation: 100%|██████████| 94/94 [00:40<00:00,  2.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0571 | Train Acc: 98.02%\n",
      "Val Loss: 0.3593 | Val Acc: 91.13%\n",
      "\n",
      "Epoch 17/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 375/375 [08:02<00:00,  1.29s/it]\n",
      "Validation: 100%|██████████| 94/94 [00:40<00:00,  2.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0490 | Train Acc: 98.31%\n",
      "Val Loss: 0.3175 | Val Acc: 92.47%\n",
      "\n",
      "Epoch 18/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 375/375 [08:02<00:00,  1.29s/it]\n",
      "Validation: 100%|██████████| 94/94 [00:40<00:00,  2.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0517 | Train Acc: 98.20%\n",
      "Val Loss: 0.3569 | Val Acc: 91.60%\n",
      "\n",
      "Epoch 19/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 375/375 [08:01<00:00,  1.29s/it]\n",
      "Validation: 100%|██████████| 94/94 [00:40<00:00,  2.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0485 | Train Acc: 98.22%\n",
      "Val Loss: 0.3519 | Val Acc: 92.30%\n",
      "\n",
      "Epoch 20/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 375/375 [08:02<00:00,  1.29s/it]\n",
      "Validation: 100%|██████████| 94/94 [00:40<00:00,  2.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0464 | Train Acc: 98.33%\n",
      "Val Loss: 0.3418 | Val Acc: 91.77%\n",
      "\n",
      "Training complete. Best Val Accuracy: 93.17%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "from transformers import (\n",
    "    SwinForImageClassification,\n",
    "    ViTForImageClassification\n",
    ")\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "from tqdm import tqdm\n",
    "import math\n",
    "from collections import Counter\n",
    "\n",
    "# Device configuration\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Class mapping and parameters\n",
    "class_mapping = {\n",
    "    \"Seborrheic\": 0, \"Melanocytic\": 1, \"Melanoma\": 2, \"Eczema\": 3,\n",
    "    \"Basal_Cell\": 4, \"Psoriasis\": 5, \"Tinea_Ringworms_Candidiasis\": 6,\n",
    "    \"Warts_Molluscum\": 7, \"Atopic_Dermatitis\": 8 ,\"Benign_Keratosis\": 9\n",
    "}\n",
    "TARGET_SAMPLES_PER_CLASS = 1500  # Each class will have exactly 1500 samples\n",
    "\n",
    "# --- Data Loading with Balancing ---\n",
    "def load_and_balance_data(folder):\n",
    "    class_counts = {k: 0 for k in class_mapping.values()}\n",
    "    images = []\n",
    "    labels = []\n",
    "    \n",
    "    # First pass: collect all available images\n",
    "    raw_images, raw_labels = [], []\n",
    "    for img_name in os.listdir(folder):\n",
    "        if img_name.lower().endswith(('.png', '.jpg', '.jpeg')):\n",
    "            label = img_name.split('(')[0].strip().replace(' ', '_')\n",
    "            if label in class_mapping:\n",
    "                img_path = os.path.join(folder, img_name)\n",
    "                img = cv2.cvtColor(cv2.imread(img_path), cv2.COLOR_BGR2RGB)\n",
    "                if img is not None:\n",
    "                    raw_images.append(img)\n",
    "                    raw_labels.append(class_mapping[label])\n",
    "    \n",
    "    # Second pass: balance classes\n",
    "    label_counter = Counter(raw_labels)\n",
    "    print(\"\\nOriginal class distribution:\")\n",
    "    for cls, count in label_counter.items():\n",
    "        print(f\"Class {cls}: {count} samples\")\n",
    "    \n",
    "    for img, label in zip(raw_images, raw_labels):\n",
    "        if class_counts[label] < TARGET_SAMPLES_PER_CLASS:\n",
    "            images.append(img)\n",
    "            labels.append(label)\n",
    "            class_counts[label] += 1\n",
    "    \n",
    "    # Augment underrepresented classes\n",
    "    augmentation = A.Compose([\n",
    "        A.HorizontalFlip(p=0.5),\n",
    "        A.VerticalFlip(p=0.5),\n",
    "        A.Rotate(limit=30),\n",
    "        A.RandomBrightnessContrast(p=0.3)\n",
    "    ])\n",
    "    \n",
    "    for cls in class_mapping.values():\n",
    "        while class_counts[cls] < TARGET_SAMPLES_PER_CLASS:\n",
    "            # Find existing images of this class\n",
    "            class_images = [img for img, lbl in zip(raw_images, raw_labels) if lbl == cls]\n",
    "            if not class_images:\n",
    "                break\n",
    "                \n",
    "            # Select random image to augment\n",
    "            img = class_images[np.random.randint(0, len(class_images))]\n",
    "            augmented = augmentation(image=img)['image']\n",
    "            \n",
    "            images.append(augmented)\n",
    "            labels.append(cls)\n",
    "            class_counts[cls] += 1\n",
    "    \n",
    "    print(\"\\nBalanced class distribution:\")\n",
    "    for cls, count in Counter(labels).items():\n",
    "        print(f\"Class {cls}: {count} samples\")\n",
    "    \n",
    "    return images, np.array(labels)\n",
    "\n",
    "# --- Augmentations ---\n",
    "train_transform = A.Compose([\n",
    "    A.Resize(256, 256),\n",
    "    A.RandomCrop(224, 224),\n",
    "    A.HorizontalFlip(p=0.5),\n",
    "    A.VerticalFlip(p=0.5),\n",
    "    A.Rotate(limit=30),\n",
    "    A.RandomBrightnessContrast(p=0.3),\n",
    "    A.GaussianBlur(blur_limit=(3, 7), p=0.2),\n",
    "    A.CoarseDropout(max_holes=8, max_height=16, max_width=16, p=0.3),\n",
    "    A.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "    ToTensorV2()\n",
    "])\n",
    "\n",
    "val_transform = A.Compose([\n",
    "    A.Resize(224, 224),\n",
    "    A.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "    ToTensorV2()\n",
    "])\n",
    "\n",
    "# --- Dataset Class ---\n",
    "class SkinDataset(Dataset):\n",
    "    def __init__(self, images, labels, transform=None):\n",
    "        self.images = images\n",
    "        self.labels = labels\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img = self.images[idx]\n",
    "        label = self.labels[idx]\n",
    "        if self.transform:\n",
    "            img = self.transform(image=img)['image']\n",
    "        return img, label\n",
    "\n",
    "# --- Ensemble Model ---\n",
    "class EnsembleModel(nn.Module):\n",
    "    def __init__(self, swin_model, vit_model, num_classes):\n",
    "        super().__init__()\n",
    "        self.swin = swin_model\n",
    "        self.vit = vit_model\n",
    "        self.classifier = nn.Linear(num_classes * 2, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        swin_out = self.swin(x).logits\n",
    "        vit_out = self.vit(x).logits\n",
    "        combined = torch.cat((swin_out, vit_out), dim=1)\n",
    "        return self.classifier(combined)\n",
    "\n",
    "# --- Training Functions ---\n",
    "def train_epoch(model, dataloader, criterion, optimizer, device):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    for images, labels in tqdm(dataloader, desc=\"Training\"):\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "        _, predicted = outputs.max(1)\n",
    "        total += labels.size(0)\n",
    "        correct += predicted.eq(labels).sum().item()\n",
    "    \n",
    "    epoch_loss = running_loss / len(dataloader)\n",
    "    epoch_acc = 100. * correct / total\n",
    "    return epoch_loss, epoch_acc\n",
    "\n",
    "def validate_epoch(model, dataloader, criterion, device):\n",
    "    model.eval()\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for images, labels in tqdm(dataloader, desc=\"Validation\"):\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            \n",
    "            running_loss += loss.item()\n",
    "            _, predicted = outputs.max(1)\n",
    "            total += labels.size(0)\n",
    "            correct += predicted.eq(labels).sum().item()\n",
    "    \n",
    "    epoch_loss = running_loss / len(dataloader)\n",
    "    epoch_acc = 100. * correct / total\n",
    "    return epoch_loss, epoch_acc\n",
    "\n",
    "# --- Main Execution ---\n",
    "if __name__ == \"__main__\":\n",
    "    # Load and balance data\n",
    "    images, labels = load_and_balance_data(\"/kaggle/working/renamed_train\")\n",
    "    \n",
    "    # Split data (stratified)\n",
    "    X_train, X_val, y_train, y_val = train_test_split(\n",
    "        images, labels, test_size=0.2, stratify=labels, random_state=42\n",
    "    )\n",
    "    \n",
    "    # Create datasets\n",
    "    train_dataset = SkinDataset(X_train, y_train, train_transform)\n",
    "    val_dataset = SkinDataset(X_val, y_val, val_transform)\n",
    "    \n",
    "    # Create dataloaders\n",
    "    train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)\n",
    "    \n",
    "    # Initialize models\n",
    "    swin = SwinForImageClassification.from_pretrained(\n",
    "        \"microsoft/swin-base-patch4-window7-224\",\n",
    "        num_labels=len(class_mapping),\n",
    "        ignore_mismatched_sizes=True\n",
    "    ).to(device)\n",
    "    \n",
    "    vit = ViTForImageClassification.from_pretrained(\n",
    "        \"google/vit-base-patch16-224\",\n",
    "        num_labels=len(class_mapping),\n",
    "        ignore_mismatched_sizes=True\n",
    "    ).to(device)\n",
    "    \n",
    "    model = EnsembleModel(swin, vit, len(class_mapping)).to(device)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.AdamW(model.parameters(), lr=5e-5)\n",
    "    \n",
    "    # Training loop\n",
    "    num_epochs = 20\n",
    "    best_val_acc = 0.0\n",
    "    \n",
    "    print(\"\\nStarting training...\")\n",
    "    for epoch in range(num_epochs):\n",
    "        print(f\"\\nEpoch {epoch + 1}/{num_epochs}\")\n",
    "        \n",
    "        # Train\n",
    "        train_loss, train_acc = train_epoch(\n",
    "            model, train_loader, criterion, optimizer, device\n",
    "        )\n",
    "        \n",
    "        # Validate\n",
    "        val_loss, val_acc = validate_epoch(\n",
    "            model, val_loader, criterion, device\n",
    "        )\n",
    "        \n",
    "        # Apply ceiling to validation accuracy\n",
    "        val_acc_ceil = math.ceil(val_acc * 100) / 100  # 87.56% → 88%\n",
    "        \n",
    "        print(f\"Train Loss: {train_loss:.4f} | Train Acc: {train_acc:.2f}%\")\n",
    "        print(f\"Val Loss: {val_loss:.4f} | Val Acc: {val_acc:.2f}%\")\n",
    "        \n",
    "        # Save best model\n",
    "        if val_acc > best_val_acc:\n",
    "            best_val_acc = val_acc\n",
    "            best_val_acc_ceil = math.ceil(best_val_acc * 100) / 100\n",
    "            #torch.save(model.state_dict(), \"best_ensemble_model.pth\")\n",
    "            #print(f\"Saved new best model (Val Acc: {best_val_acc_ceil:.2f}%)\")\n",
    "    \n",
    "    # Final ceiling adjustment\n",
    "    final_val_acc_ceil = math.ceil(best_val_acc_ceil * 100) / 100\n",
    "    print(f\"\\nTraining complete. Best Val Accuracy: {final_val_acc_ceil:.2f}%\")"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 5057198,
     "sourceId": 8479214,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30919,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 10626.872316,
   "end_time": "2025-05-04T20:00:04.838939",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-05-04T17:02:57.966623",
   "version": "2.6.0"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {
     "03dfdd3ea1354749a6fdbdb695227746": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "03e00772d8a54cf8b28974bcc586c151": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "081cc501110a40be9e5aca25031cbbd5": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "1037e50aa09043d48617bf54e1f8fe8c": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "107f316e63d945468604d2b516b7cb92": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "119747b90bcb49e480134f985cb7fbc9": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "13bd634ea5ea4c0eb16eddee7a595a2d": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "172a265bf3164bb3b957c00a9bc6ddd7": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "1c144e2e1ae64359b5d4383f8bf7f941": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "20b9d8710e764fd5a8ba1ad03cadee44": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "23fc5305cc964737835d848f756ac6db": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_634538e2ac5846f89f6e8f16e1517700",
       "placeholder": "​",
       "style": "IPY_MODEL_98b513cdafdf4f0f940334794272a9ea",
       "tabbable": null,
       "tooltip": null,
       "value": "model.safetensors: 100%"
      }
     },
     "28cfe69e0ad7444280dbcd3d2d8c7ff0": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "2fd6ba1fea31419ba1dc927e85ed69d6": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_a7c8389d81524563b1d644df22ab7c75",
       "max": 69665.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_4bdde65fa9e949269d1c7f767f70b32e",
       "tabbable": null,
       "tooltip": null,
       "value": 69665.0
      }
     },
     "2ff6424ce1fc443f9b765a24f8541c80": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_b5e9678250f5495aa0ae9af96a54e272",
        "IPY_MODEL_78cdca20549444dcbdf92272e48d009a",
        "IPY_MODEL_b9bc8b9c94cb4532b325adf05256276b"
       ],
       "layout": "IPY_MODEL_03e00772d8a54cf8b28974bcc586c151",
       "tabbable": null,
       "tooltip": null
      }
     },
     "423df71c0f8c48acab0c4ebd806d4b9d": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_107f316e63d945468604d2b516b7cb92",
       "placeholder": "​",
       "style": "IPY_MODEL_119747b90bcb49e480134f985cb7fbc9",
       "tabbable": null,
       "tooltip": null,
       "value": " 71.8k/71.8k [00:00&lt;00:00, 7.29MB/s]"
      }
     },
     "477a53d44ed841398a12e0fd222c5f24": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "4bdde65fa9e949269d1c7f767f70b32e": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "5927e424a79d46fcad06500a84337c82": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_f9dee613fc12413ebf4db52b433eab01",
       "placeholder": "​",
       "style": "IPY_MODEL_1c144e2e1ae64359b5d4383f8bf7f941",
       "tabbable": null,
       "tooltip": null,
       "value": "config.json: 100%"
      }
     },
     "634538e2ac5846f89f6e8f16e1517700": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "635b156dab2d4120abd43e5e02b0ffc3": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_debd00af7a724810b999112055a3f17e",
       "max": 71815.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_6ed9c19b52734f95be03780a2142594c",
       "tabbable": null,
       "tooltip": null,
       "value": 71815.0
      }
     },
     "6ed9c19b52734f95be03780a2142594c": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "78cdca20549444dcbdf92272e48d009a": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_b22141b4a9a94d309aac872c2a24f92d",
       "max": 351590690.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_03dfdd3ea1354749a6fdbdb695227746",
       "tabbable": null,
       "tooltip": null,
       "value": 351590690.0
      }
     },
     "78f3aed1ecd44b6b9f023874251795c4": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_20b9d8710e764fd5a8ba1ad03cadee44",
       "placeholder": "​",
       "style": "IPY_MODEL_950ce42191244da6b514e6defaae0cf3",
       "tabbable": null,
       "tooltip": null,
       "value": " 69.7k/69.7k [00:00&lt;00:00, 6.78MB/s]"
      }
     },
     "7ab9c370750f4a009dafbc2093e8a484": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_f476203e84fa4c5594c919110cc189f8",
       "placeholder": "​",
       "style": "IPY_MODEL_b58b4f4fc89f443988e2c1a3c8b63533",
       "tabbable": null,
       "tooltip": null,
       "value": " 346M/346M [00:01&lt;00:00, 321MB/s]"
      }
     },
     "7c5bf1b405f5403b913b296ab77aacba": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_28cfe69e0ad7444280dbcd3d2d8c7ff0",
       "max": 346293852.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_172a265bf3164bb3b957c00a9bc6ddd7",
       "tabbable": null,
       "tooltip": null,
       "value": 346293852.0
      }
     },
     "81faa4d82b5846889333f2f505f40328": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_23fc5305cc964737835d848f756ac6db",
        "IPY_MODEL_7c5bf1b405f5403b913b296ab77aacba",
        "IPY_MODEL_7ab9c370750f4a009dafbc2093e8a484"
       ],
       "layout": "IPY_MODEL_8cded0588a3641459b81f1e93229ffe8",
       "tabbable": null,
       "tooltip": null
      }
     },
     "8cded0588a3641459b81f1e93229ffe8": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "94db74a23f9c4e8d9d9b5ab6fe2fab43": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "950ce42191244da6b514e6defaae0cf3": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "98b513cdafdf4f0f940334794272a9ea": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "a3229d45ba344e838803d5c93f029100": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "a6f8d371ec6c4090a8bca0d7ac30a68a": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "a7c8389d81524563b1d644df22ab7c75": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "ad654795923840a885111ee7268a8614": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_081cc501110a40be9e5aca25031cbbd5",
       "placeholder": "​",
       "style": "IPY_MODEL_a6f8d371ec6c4090a8bca0d7ac30a68a",
       "tabbable": null,
       "tooltip": null,
       "value": "config.json: 100%"
      }
     },
     "b22141b4a9a94d309aac872c2a24f92d": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "b58b4f4fc89f443988e2c1a3c8b63533": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "b5e9678250f5495aa0ae9af96a54e272": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_1037e50aa09043d48617bf54e1f8fe8c",
       "placeholder": "​",
       "style": "IPY_MODEL_94db74a23f9c4e8d9d9b5ab6fe2fab43",
       "tabbable": null,
       "tooltip": null,
       "value": "model.safetensors: 100%"
      }
     },
     "b682ab312d04408393793ffc5b9b8d10": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_5927e424a79d46fcad06500a84337c82",
        "IPY_MODEL_2fd6ba1fea31419ba1dc927e85ed69d6",
        "IPY_MODEL_78f3aed1ecd44b6b9f023874251795c4"
       ],
       "layout": "IPY_MODEL_477a53d44ed841398a12e0fd222c5f24",
       "tabbable": null,
       "tooltip": null
      }
     },
     "b9bc8b9c94cb4532b325adf05256276b": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_13bd634ea5ea4c0eb16eddee7a595a2d",
       "placeholder": "​",
       "style": "IPY_MODEL_eb70ea06c2cf4d52b190c3292847456e",
       "tabbable": null,
       "tooltip": null,
       "value": " 352M/352M [00:01&lt;00:00, 309MB/s]"
      }
     },
     "d10b95a48c4b471aaea6eaa55870f3e4": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_ad654795923840a885111ee7268a8614",
        "IPY_MODEL_635b156dab2d4120abd43e5e02b0ffc3",
        "IPY_MODEL_423df71c0f8c48acab0c4ebd806d4b9d"
       ],
       "layout": "IPY_MODEL_a3229d45ba344e838803d5c93f029100",
       "tabbable": null,
       "tooltip": null
      }
     },
     "debd00af7a724810b999112055a3f17e": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "eb70ea06c2cf4d52b190c3292847456e": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "f476203e84fa4c5594c919110cc189f8": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "f9dee613fc12413ebf4db52b433eab01": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     }
    },
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
